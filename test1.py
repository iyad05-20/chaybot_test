# ===================================
# CHATBOT GEMINI AVEC STREAMLIT
# Version simple et compl√®te
# ===================================

"""
Installation :
    pip install streamlit google-generativeai python-dotenv

Lancer :
    streamlit run app.py

Cr√©er un fichier .env :
    GEMINI_API_KEY=votre_cl√©_ici
"""

import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv

# Configuration de la page
st.set_page_config(
    page_title="Recommendation Chatbot",
    page_icon="ü§ñ",
    layout="centered"
)

# Charger la cl√© API
load_dotenv("test.env")
api_key = os.getenv('GEMINI_API_KEY')

# V√©rifier la cl√© API
if not api_key:
    st.error("‚ùå Cl√© API non trouv√©e ! Ajoutez GEMINI_API_KEY dans votre fichier .env")
    st.stop()

# Configurer Gemini
genai.configure(api_key=api_key)

# ===================================
# INTERFACE UTILISATEUR
# ===================================

# Titre
st.title("ü§ñ Recommendation Chatbot")
st.markdown("Cherchez votre MEILLEUR artisan !")
st.markdown("*Donnez des questions, le chatbot est ici pour te repondre.*")

# ===================================
# SIDEBAR (Barre lat√©rale)
# ===================================

with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres")
    
    # Temp√©rature
    temperature = st.slider(
        "Cr√©ativit√©",
        min_value=0.0,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="0.0 = Pr√©cis | 1.0 = Cr√©atif"
    )
    
    # Max tokens
    max_tokens = st.number_input(
        "Longueur max",
        min_value=100,
        max_value=2000,
        value=1000,
        step=100,
        help="Nombre maximum de mots dans la r√©ponse"
    )
    
    
    st.divider()
    
    # Statistiques
    st.markdown("### üìä Statistiques")
    if 'messages' in st.session_state:
        nb_messages = len(st.session_state.messages) // 2
        st.metric("Messages envoy√©s", nb_messages)
    
    st.divider()
    
    # Bouton pour effacer
    if st.button("üóëÔ∏è Effacer la conversation", use_container_width=True):
        st.session_state.messages = []
        if 'chat' in st.session_state:
            del st.session_state.chat
        st.rerun()

# ===================================
# INITIALISATION
# ===================================

# Initialiser le mod√®le
if 'model' not in st.session_state:
    st.session_state.model = genai.GenerativeModel(
        'gemini-2.5-flash',
        generation_config={
            'temperature': temperature,
            'max_output_tokens': max_tokens
        }
    )
    st.session_state.chat = st.session_state.model.start_chat(history=[])

# Initialiser l'historique des messages
if 'messages' not in st.session_state:
    st.session_state.messages = []

# ===================================
# AFFICHAGE DE L'HISTORIQUE
# ===================================

# Afficher tous les messages pr√©c√©dents
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ===================================
# INPUT UTILISATEUR ET R√âPONSE
# ===================================

# Zone de saisie du chat
if prompt := st.chat_input("Posez votre question..."):
    
    # Ajouter et afficher le message utilisateur
    st.session_state.messages.append({
        "role": "user",
        "content": prompt
    })
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # G√©n√©rer et afficher la r√©ponse
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        try:
            # Envoyer le message √† Gemini
            response = st.session_state.chat.send_message(prompt)
            full_response = response.text
            
            # Afficher la r√©ponse
            message_placeholder.markdown(full_response)
            
            # Ajouter la r√©ponse √† l'historique
            st.session_state.messages.append({
                "role": "assistant",
                "content": full_response
            })
        
        except Exception as e:
            error_message = f"‚ùå Erreur : {str(e)}"
            message_placeholder.error(error_message)
            
            # Messages d'erreur sp√©cifiques
            if "quota" in str(e).lower():
                st.warning("‚ö†Ô∏è Limite d'API atteinte. Attendez un peu.")
            elif "invalid" in str(e).lower():
                st.error("üîë Cl√© API invalide. V√©rifiez votre .env")

# ===================================
# FOOTER
# ===================================

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 0.8em;'>
        Cr√©√© avec ‚ù§Ô∏è | Propuls√© par Gemini API
    </div>
    """,
    unsafe_allow_html=True
)


